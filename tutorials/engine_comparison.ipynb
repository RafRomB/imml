{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad7e6e7-8de6-406a-b68a-3e5b772b7fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alberto/PycharmProjects/incomplete_multiview_clustering\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b6ce94-1b5a-4117-b434-e67de5f44be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imvc.datasets import LoadDataset\n",
    "from imvc.ampute import Amputer\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm\n",
    "from time import perf_counter\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d14e41a-30a4-4a04-bcdf-394df5bd0adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tueplots import axes, bundles\n",
    "plt.rcParams.update({**bundles.icml2022(), **axes.lines()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1483b89c-daa6-45a0-89c7-074ce53b3fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_engine_comp(results_dict, Xs, y, n_clusters, estimator, engines, ps, n_times):\n",
    "    for p in ps:\n",
    "        missing_percentge = int(p*100)\n",
    "        results_dict[missing_percentge] = {}\n",
    "        matrices_comp = {}\n",
    "        amputed_Xs = Amputer(p=p, mechanism=\"mcar\", random_state=42).fit_transform(Xs)\n",
    "        for engine in engines:\n",
    "            results_dict[missing_percentge][engine] = {}\n",
    "            matrices_comp[engine] = []\n",
    "            for i in range(n_times):\n",
    "                results_dict[missing_percentge][engine][i] = {}\n",
    "                estimator.set_params(n_clusters=n_clusters, engine=engine, random_state=i)\n",
    "                start_time = perf_counter()\n",
    "                try:\n",
    "                    labels = estimator.fit_predict(amputed_Xs)\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    continue\n",
    "                results_dict[missing_percentge][engine][i][\"Computing time\"] = perf_counter() - start_time\n",
    "                results_dict[missing_percentge][engine][i][\"AMI\"] = adjusted_mutual_info_score(labels_true=y, labels_pred=labels)\n",
    "                results_dict[missing_percentge][engine][i][\"ARI\"] = adjusted_rand_score(labels_true=y, labels_pred=labels)\n",
    "                try:\n",
    "                    embeddings = True\n",
    "                    matrices_comp[engine].append(estimator.embedding_)\n",
    "                except:\n",
    "                    pass\n",
    "        if embeddings:\n",
    "            results_dict[missing_percentge][\"both\"] = {}\n",
    "            results_dict[missing_percentge][\"both\"][0] = {}\n",
    "            for engine in engines + [\"both\"]: \n",
    "                results_dict[missing_percentge][engine][0][\"RMSE\"] = []\n",
    "                results_dict[missing_percentge][engine][0][\"MAE\"] = []\n",
    "                if engine == \"both\":\n",
    "                    mats = [mat for mats in matrices_comp.values() for mat in mats]\n",
    "                else:\n",
    "                    mats = matrices_comp[engine]\n",
    "                combs = set(itertools.combinations(range(len(mats)), 2))\n",
    "                combs = [(mats[comb[0]], mats[comb[1]]) for comb in combs]\n",
    "                for i, (mat1, mat2) in enumerate(combs):\n",
    "                    results_dict[missing_percentge][engine][0][\"RMSE\"].append(mean_squared_error(y_true=mat1, y_pred=mat2, squared=False))\n",
    "                    results_dict[missing_percentge][engine][0][\"MAE\"].append(mean_absolute_error(y_true=mat1, y_pred=mat2))\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af95e6ec-c18a-4db2-97b7-c3b21898185c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engine_comp(datasets, estimator, engines, ps, n_times):\n",
    "    results = {}\n",
    "    for dataset in tqdm(datasets):\n",
    "        names = dataset.split(\"_\")\n",
    "        if \"simulated\" in names:\n",
    "            names = [\"_\".join(names)]\n",
    "        x_name,y_name = names if len(names) > 1 else (names[0], \"0\")\n",
    "        Xs, y = LoadDataset.load_dataset(dataset_name=x_name, return_y=True)\n",
    "        y = y[y_name]\n",
    "        n_clusters = int(y.nunique())\n",
    "        \n",
    "        results[dataset] = {}\n",
    "        results[dataset] = dataset_engine_comp(results_dict= results[dataset], Xs=Xs, y=y, n_clusters=n_clusters,\n",
    "                                      estimator=estimator, engines=engines, ps=ps, n_times=n_times)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d2d0c-80ba-4144-9658-0d52d8af0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine_comp(datasets= [\"nutrimouse_genotype\", \"buaa\", \"bdgp\", \"bbcsport\", \"sensIT300\"],\n",
    "                      estimator=estimator, engines= [\"python\", \"matlab\"], ps= np.arange(0., 0.7, 0.2), n_times = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a4030-8dea-4876-926b-e6b384e6bd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37444040ff6143b383a04f163fcb85af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: matrix singular to machine precision, rcond = 6.76372e-17\n",
      "warning: called from\n",
      "    newinit at line 41 column 10\n",
      "    _pyeval at line 57 column 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imvc.cluster import DAIMC\n",
    "estimator_name = \"DAIMC\"\n",
    "estimator = DAIMC()\n",
    "results = engine_comp(datasets= [\"nutrimouse_genotype\", \"buaa\", \"bdgp\", \"bbcsport\", \"sensIT300\"],\n",
    "                      estimator=estimator, engines= [\"python\", \"matlab\"], ps= np.arange(0., 0.7, 0.2), n_times = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38463a5-df3d-47c6-8c77-aba19d5ed722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattened_data = [\n",
    "    {\n",
    "        'Dataset': dataset,\n",
    "        'Incomplete samples (\\%)': p,\n",
    "        'Engine': engine,\n",
    "        'Iteration': i,\n",
    "        **iter_dict\n",
    "    }\n",
    "    for dataset, dataset_dict in results.items()\n",
    "    for p, p_dict in dataset_dict.items()\n",
    "    for engine, engine_dict in p_dict.items()\n",
    "    for i, iter_dict in engine_dict.items()\n",
    "]\n",
    "results = pd.DataFrame(flattened_data)\n",
    "results.to_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\", index= None)\n",
    "print(\"results\", results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f95f99-0a6f-4d5d-aa82-ec66a02572d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\")\n",
    "results[\"Engine\"] = results[\"Engine\"].replace({\"python\": \"Python\", \"matlab\": \"Matlab\", \"both\": \"Both\"})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b78ec-4603-4db0-9d4c-a382f8ee5d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_engine = results.dropna().groupby([\"Dataset\", \"Engine\"], as_index=False)[\"Computing time\"].mean().set_index(\"Dataset\")\n",
    "time_engine = time_engine.pivot(columns=\"Engine\")\n",
    "time_engine.columns = time_engine.columns.droplevel(0)\n",
    "time_engine.columns.name = None\n",
    "time_engine[\"Speed-up\"] = time_engine[\"Matlab\"] / time_engine[\"Python\"]\n",
    "time_engine = time_engine.round(1)\n",
    "time_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b54fe2-0e75-42ca-aa71-78df1b2d5a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.loc[results[\"Iteration\"] == 0, \"RMSE\"] = results.loc[results[\"Iteration\"] == 0, \"RMSE\"].apply(eval)\n",
    "results.loc[results[\"Iteration\"] == 0, \"MAE\"] = results.loc[results[\"Iteration\"] == 0, \"MAE\"].apply(eval)\n",
    "\n",
    "stability_results = []\n",
    "for _, row in results[results[\"Iteration\"] == 0].iterrows():\n",
    "    for rmse, mae in zip(row[\"RMSE\"], row[\"MAE\"]):\n",
    "        stability_results.append([row[\"Dataset\"], row[\"Engine\"], row[\"Incomplete samples (\\%)\"], rmse, mae])\n",
    "\n",
    "stability_results = pd.DataFrame(stability_results, columns= [\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\", \"RMSE\", \"MAE\"])\n",
    "\n",
    "results = results.set_index([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"]).drop(columns= [\"Iteration\", \"Computing time\", \"RMSE\", \"MAE\"])\n",
    "stability_results = stability_results.set_index([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"])\n",
    "results = results.join(stability_results, how=\"right\").reset_index()\n",
    "results = results.melt(id_vars= [\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"], var_name='Metric', value_name='Value')\n",
    "results = results.sort_values([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"], ascending=[True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e453b2-c6ef-436d-a6b0-3bb37344872c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.FacetGrid(data=results, row=\"Metric\", col= \"Dataset\", dropna=True, legend_out=False, sharey=True).map_dataframe(\n",
    "    sns.boxplot, x=\"Incomplete samples (\\%)\", y= \"Value\", hue= \"Engine\", palette= \"tab10\", showmeans=True,\n",
    "    meanprops={'markerfacecolor':'cyan', 'markeredgecolor':'cyan'})\n",
    "ax.add_legend()\n",
    "plt.savefig(f\"engine_comparison_{estimator_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b82e4-1fce-4403-b40f-719fc48491dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
