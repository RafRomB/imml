{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7e6e7-8de6-406a-b68a-3e5b772b7fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6ce94-1b5a-4117-b434-e67de5f44be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm\n",
    "from time import perf_counter\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from datasets import LoadDataset\n",
    "from imml.ampute import Amputer\n",
    "from imml.cluster import DAIMC, IMSR, LFIMVC, EEIMVC, SIMCADC, NEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14e41a-30a4-4a04-bcdf-394df5bd0adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tueplots import axes, bundles\n",
    "plt.rcParams.update({**bundles.icml2022(), **axes.lines()})\n",
    "for key in [\"axes.labelsize\", \"axes.titlesize\", \"font.size\", \"legend.fontsize\", \"xtick.labelsize\", \"ytick.labelsize\"]:\n",
    "    if key == \"legend.fontsize\":\n",
    "        plt.rcParams[key] += 4\n",
    "    else:\n",
    "        plt.rcParams[key] += 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483b89c-daa6-45a0-89c7-074ce53b3fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_engine_comp(results_dict, Xs, y, n_clusters, estimator, engines, ps, n_times, att_matrix):\n",
    "    embeddings = False\n",
    "    for p in tqdm(ps):\n",
    "        missing_percentge = int(p*100)\n",
    "        results_dict[missing_percentge] = {}\n",
    "        matrices_comp = {}\n",
    "        amputed_Xs = Amputer(p=p, mechanism=\"mcar\", random_state=42).fit_transform(Xs)\n",
    "        for engine in engines:\n",
    "            results_dict[missing_percentge][engine] = {}\n",
    "            matrices_comp[engine] = []\n",
    "            for i in range(n_times):\n",
    "                results_dict[missing_percentge][engine][i] = {}\n",
    "                start_time = perf_counter()\n",
    "                try:\n",
    "                    model = estimator(n_clusters=n_clusters, engine=engine, random_state=i)\n",
    "                    labels = model.fit_predict(amputed_Xs)\n",
    "                except Exception as ex:\n",
    "                    results_dict[missing_percentge][engine][i][\"Comments\"] = ex\n",
    "                    continue\n",
    "                results_dict[missing_percentge][engine][i][\"Computing time\"] = perf_counter() - start_time\n",
    "                ami = adjusted_mutual_info_score(labels_true=y, labels_pred=labels)\n",
    "                ari = adjusted_rand_score(labels_true=y, labels_pred=labels)\n",
    "                results_dict[missing_percentge][engine][i][\"Adjusted Mutual Information (AMI)\"] = ami\n",
    "                results_dict[missing_percentge][engine][i][\"Adjusted Rand Index (ARI)\"] = ari\n",
    "                try:\n",
    "                    embeddings = True\n",
    "                    mat = getattr(model, att_matrix)\n",
    "                    matrices_comp[engine].append(mat)\n",
    "                except:\n",
    "                    pass\n",
    "                results_dict[missing_percentge][engine][i][\"Comments\"] = \"\"\n",
    "        if embeddings:\n",
    "            results_dict[missing_percentge][\"both\"] = {}\n",
    "            results_dict[missing_percentge][\"both\"][0] = {}\n",
    "            for engine in engines + [\"both\"]: \n",
    "                results_dict[missing_percentge][engine][0][\"Root Mean Squared Error (RMSE)\"] = []\n",
    "                results_dict[missing_percentge][engine][0][\"Mean Absolute Error (MAE)\"] = []\n",
    "                if engine == \"both\":\n",
    "                    mats = [mat for mats in matrices_comp.values() for mat in mats]\n",
    "                else:\n",
    "                    mats = matrices_comp[engine]\n",
    "                combs = set(itertools.combinations(range(len(mats)), 2))\n",
    "                combs = [(mats[comb[0]], mats[comb[1]]) for comb in combs]\n",
    "                for i, (mat1, mat2) in enumerate(combs):\n",
    "                    rmse = mean_squared_error(y_true=mat1, y_pred=mat2, squared=False)\n",
    "                    mae = mean_absolute_error(y_true=mat1, y_pred=mat2)\n",
    "                    results_dict[missing_percentge][engine][0][\"Root Mean Squared Error (RMSE)\"].append(rmse)\n",
    "                    results_dict[missing_percentge][engine][0][\"Mean Absolute Error (MAE)\"].append(mae)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95e6ec-c18a-4db2-97b7-c3b21898185c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engine_comp(datasets, estimator, engines, ps, n_times, att_matrix):\n",
    "    results = {}\n",
    "    for dataset in tqdm(datasets):\n",
    "        names = dataset.split(\"_\")\n",
    "        if \"simulated\" in names:\n",
    "            names = [\"_\".join(names)]\n",
    "        x_name,y_name = names if len(names) > 1 else (names[0], \"0\")\n",
    "        Xs, y = LoadDataset.load_dataset(dataset_name=x_name, return_y=True)\n",
    "        y = y[y_name]\n",
    "        n_clusters = int(y.nunique())\n",
    "        \n",
    "        results[dataset] = {}\n",
    "        results[dataset] = dataset_engine_comp(results_dict= results[dataset], Xs=Xs, y=y, n_clusters=n_clusters,\n",
    "                                               estimator=estimator, engines=engines, ps=ps, n_times=n_times,\n",
    "                                               att_matrix=att_matrix)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc9d20-a326-4b2c-a07b-2cf83452b15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_results(results, estimator_name, values_to_replace):\n",
    "    flattened_data = [\n",
    "    {\n",
    "        'Dataset': dataset,\n",
    "        'Incomplete samples (\\%)': p,\n",
    "        'Engine': engine,\n",
    "        'Iteration': i,\n",
    "        **iter_dict\n",
    "    }\n",
    "    for dataset, dataset_dict in results.items()\n",
    "    for p, p_dict in dataset_dict.items()\n",
    "    for engine, engine_dict in p_dict.items()\n",
    "    for i, iter_dict in engine_dict.items()\n",
    "]\n",
    "    results = pd.DataFrame(flattened_data)\n",
    "    for col_name, replacing_dict in values_to_replace.items():\n",
    "        results[col_name] = results[col_name].replace(replacing_dict)\n",
    "    if estimator_name is not None:\n",
    "        results.to_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\", index= None)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa96c2-984e-4675-a0da-08fd3546f3af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimator_time_comp(results, estimator_name, language_comparison):\n",
    "    results[\"Estimator\"] = estimator_name\n",
    "    results = results[results[\"Engine\"] != \"Both\"]\n",
    "    for engine in results[\"Engine\"].unique():\n",
    "        mask = (results[\"Engine\"] == engine) & (results[\"Comments\"].notnull())\n",
    "        mask = results.loc[mask, [\"Dataset\", \"Incomplete samples (\\%)\", \"Iteration\"]]\n",
    "        mask = mask.set_index([\"Dataset\", \"Incomplete samples (\\%)\", \"Iteration\"]).index\n",
    "        mask = results.set_index([\"Dataset\", \"Incomplete samples (\\%)\", \"Iteration\"]).drop(labels=mask)\n",
    "        results = mask.reset_index()\n",
    "    time_engine = results.drop(columns=\"Comments\")\n",
    "    assert time_engine[\"Adjusted Mutual Information (AMI)\"].notnull().all()\n",
    "    time_engine = time_engine.groupby([\"Estimator\", \"Dataset\", \"Engine\"], as_index=False)[\"Computing time\"].mean()\n",
    "    time_engine = time_engine.set_index([\"Estimator\", \"Dataset\"])\n",
    "    time_engine = time_engine.pivot(columns=\"Engine\")\n",
    "    time_engine.columns = time_engine.columns.droplevel(0)\n",
    "    time_engine.columns.name = None\n",
    "    time_engine[\"Speed-up\"] = time_engine[language_comparison.capitalize()] / time_engine[\"Python\"]\n",
    "    return time_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef4ed1-1309-4e03-ad28-b2f6a20c74ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_comp(estimator_list):\n",
    "    time_engine = [estimator_time_comp(results=pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\"),\n",
    "                                   language_comparison=language_comparison, estimator_name=estimator_name)\n",
    "                   for (estimator_name, language_comparison, _) in estimator_list]\n",
    "    time_engine = pd.concat(time_engine)\n",
    "    time_engine = time_engine[['Python'] + [c for c in time_engine.columns if c not in ['Python', 'Speed-up']] + ['Speed-up']]\n",
    "    time_engine = time_engine.groupby([\"Estimator\"]).agg(['mean', lambda x: (x.min().round(1), x.max().round(1))])\n",
    "    time_engine = time_engine.round(1).sort_values((\"Speed-up\", \"mean\"), ascending=False)\n",
    "    time_engine.columns = pd.MultiIndex.from_tuples(\n",
    "        [(col1, 'Average' if col2 == 'mean' else '(Min, Max)' if col2 == '<lambda_0>' else col2)\n",
    "         for col1, col2 in time_engine.columns]\n",
    "    )\n",
    "    return time_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc86684-029d-4857-a148-619301a785cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_visualizations(results):\n",
    "    results = results[results[\"Comments\"].isna()]\n",
    "    results = results.drop(columns=\"Comments\")\n",
    "    for metric in [\"Root Mean Squared Error (RMSE)\", \"Mean Absolute Error (MAE)\"]:\n",
    "        results.loc[results[\"Iteration\"] == 0, metric] = results.loc[results[\"Iteration\"] == 0, metric].apply(eval)\n",
    "\n",
    "    stability_results = []\n",
    "    for _, row in results[results[\"Iteration\"] == 0].iterrows():\n",
    "        for rmse, mae in zip(row[\"Root Mean Squared Error (RMSE)\"], row[\"Mean Absolute Error (MAE)\"]):\n",
    "            stability_results.append([row[\"Dataset\"], row[\"Engine\"], row[\"Incomplete samples (\\%)\"], rmse, mae])\n",
    "\n",
    "    stability_results = pd.DataFrame(stability_results,\n",
    "                                     columns= [\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\",\n",
    "                                               \"Root Mean Squared Error (RMSE)\", \"Mean Absolute Error (MAE)\"])\n",
    "\n",
    "    results = results.set_index([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"])\n",
    "    results = results.drop(columns= [\"Iteration\", \"Computing time\", \"Root Mean Squared Error (RMSE)\", \"Mean Absolute Error (MAE)\"])\n",
    "    stability_results = stability_results.set_index([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"])\n",
    "    results = results.join(stability_results, how=\"right\").reset_index()\n",
    "    results = results.melt(id_vars= [\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"], var_name='Metric', value_name='Value')\n",
    "    results = results.sort_values([\"Dataset\", \"Engine\", \"Incomplete samples (\\%)\"], ascending=[True, False, True])\n",
    "    results[\"Metric\"] = results[\"Metric\"].replace({\n",
    "        \"Adjusted Mutual Information (AMI)\": \"Adjusted Mutual Information\",\n",
    "        \"Adjusted Rand Index (ARI)\": \"Adjusted Rand Index\",\n",
    "        \"Root Mean Squared Error (RMSE)\": \"Root Mean Squared Error\",\n",
    "        \"Mean Absolute Error (MAE)\": \"Mean Absolute Error\",\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ad66-45f4-4eaa-81ad-54e5c2db4365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_list = [\n",
    "    (\"EEIMVC\", \"matlab\", \"embedding_\"),\n",
    "    (\"SIMCADC\", \"matlab\", \"embedding_\"),\n",
    "    (\"LFIMVC\", \"matlab\", \"embedding_\"),\n",
    "    (\"NEMO\", \"r\", \"affinity_matrix_\"),\n",
    "    (\"IMSR\", \"matlab\", \"embedding_\"),\n",
    "    (\"DAIMC\", \"matlab\", \"embedding_\"),\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    \"nutrimouse_genotype\",\n",
    "    \"sensIT300\",\n",
    "    \"buaa\",\n",
    "    \"bbcsport\",\n",
    "    \"bdgp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b4d50-5769-46f5-b46e-280ad4a34315",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (estimator_name, language_comparison, att_matrix) in estimator_list:\n",
    "    results = engine_comp(datasets= datasets,\n",
    "                          estimator=eval(estimator_name), engines= [\"python\", language_comparison],\n",
    "                          ps= np.arange(0., 0.7, 0.2), n_times = 50, att_matrix=att_matrix)\n",
    "    results = process_results(results=results, estimator_name=estimator_name, values_to_replace={\n",
    "        \"Engine\": {\"python\": \"Python\", \"matlab\": \"Matlab\", \"r\": \"R\", \"both\": \"Both\"},\n",
    "        \"Dataset\": {\"bbcsport\": \"BBCSport\", \"bdgp\": \"BDGP\", \"buaa\": \"BUAA\", \"nutrimouse_genotype\": \"Nutrimouse\"},\n",
    "    })\n",
    "#    results = pd.concat([pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\"), results])\n",
    "#    results.to_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\", index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c3d26-9122-4886-bdca-d04155c108e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_engine = time_comp(estimator_list=estimator_list)\n",
    "time_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f6712-5c3f-4b4d-83fa-9a59facf5b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(time_engine.applymap(lambda x: \"-\" if np.isnan(x).all() else x).fillna(\"-\").to_latex(float_format=lambda x: round(x, 1), column_format=\"l|cc|cc|cc|cc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72fe97-9674-46b4-b9d6-e3df7220d67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_name = \"DAIMC\"\n",
    "language_comparison = [i[1] for i in estimator_list if i[0] == estimator_name][0]\n",
    "results = pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\")\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e85e03-5cc0-496e-8302-da8eec14e485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_engine = [estimator_time_comp(pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\"), estimator_name, language_comparison)\n",
    "               for (estimator_name, language_comparison, _) in estimator_list]\n",
    "time_engine = pd.concat(time_engine).loc[:, [\"Python\", \"Matlab\", \"R\", \"Speed-up\"]]\n",
    "print(time_engine.fillna(\"-\").to_latex(float_format=lambda x: round(x, 1), column_format=\"llcccc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2d634-f575-4b69-b440-7c4919fe7af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_time_comp(results.copy(), estimator_name, language_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1762f13-ee43-47e1-905b-8b27a54d5cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = results[results[\"Comments\"].notnull()]\n",
    "print(\"errors\", errors.shape)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4f54e-4721-420a-8118-c905b3ef5d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors[[\"Engine\", \"Comments\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b54fe2-0e75-42ca-aa71-78df1b2d5a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = prepare_visualizations(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e453b2-c6ef-436d-a6b0-3bb37344872c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# axes = sns.FacetGrid(data=results, row=\"Metric\", col= \"Dataset\", dropna=True, legend_out=False,\n",
    "#                      sharey=False, despine=False).map_dataframe(\n",
    "#     sns.boxplot, x=\"Incomplete samples (\\%)\", y= \"Value\", hue= \"Engine\", palette= \"colorblind\",\n",
    "#     hue_order=[\"Python\", language_comparison.capitalize(), \"Both\"], showmeans=True,\n",
    "#     meanprops={'markerfacecolor':'white', 'markeredgecolor':'black'})\n",
    "# axes.add_legend()\n",
    "# for ax, ylabel in zip(axes.axes[:, 0], results[\"Metric\"].unique()):\n",
    "#     ax.set_ylabel(ylabel)\n",
    "# for ax in axes.axes.flatten():\n",
    "#     if (\"AMI\" in ax.get_title()) or (\"ARI\" in ax.get_title()):\n",
    "#         ax.set_ylim(-0.05, 1.05)\n",
    "#     ax.set_title(\"\")\n",
    "# for ax, title in zip(axes.axes[0, :], results[\"Dataset\"].unique()):\n",
    "#     ax.set_title(title)\n",
    "# for i in range(results[\"Metric\"].nunique()):   \n",
    "#     for j in range(1, results[\"Dataset\"].nunique()):   \n",
    "#         axes.axes[i,j].get_yaxis().set_visible(False)\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f\"engine_comparison_{estimator_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c593bf-f025-4257-a246-2b4560138da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colorblind_palette = sns.color_palette(\"colorblind\")\n",
    "color_language_idx = 1 if language_comparison == \"matlab\" else 3\n",
    "colorblind_palette = [colorblind_palette[0]] + [colorblind_palette[color_language_idx]] + [colorblind_palette[4]]\n",
    "axes = sns.FacetGrid(data=results.drop_duplicates(), row=\"Metric\", \n",
    "                     col= \"Dataset\", dropna=True, legend_out=False,\n",
    "                     sharey=False, despine=False).map_dataframe(\n",
    "    sns.pointplot, x=\"Incomplete samples (\\%)\", y= \"Value\", hue= \"Engine\",\n",
    "    palette= colorblind_palette,\n",
    "    hue_order=[\"Python\", language_comparison.capitalize(), \"Both\"], linestyles= [\"-\", \"--\", \":\"],\n",
    "    capsize= 0.05, seed= 42)\n",
    "\n",
    "ax_legend = axes.axes.flatten()[0]\n",
    "handles = [plt.Line2D([0], [0], color=col, lw=2, linestyle=linestyle)\n",
    "           for col, linestyle in zip(colorblind_palette, [\"-\", \"--\", \":\"])]\n",
    "new_legend = ax_legend.legend(handles=handles, \n",
    "                              labels=results[\"Engine\"].unique().tolist(),\n",
    "                              title=\"Engine\", loc=\"upper right\")\n",
    "ax_legend.add_artist(new_legend)\n",
    "\n",
    "\n",
    "for ax, ylabel in zip(axes.axes[:, 0], results[\"Metric\"].unique()):\n",
    "    ax.set_ylabel(ylabel)\n",
    "for ax in axes.axes.flatten():\n",
    "    if \"Adjusted\" in ax.get_title():\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "    ax.set_title(\"\")\n",
    "for ax, title in zip(axes.axes[0, :], results[\"Dataset\"].unique()):\n",
    "    ax.set_title(title)\n",
    "for i in range(results[\"Metric\"].nunique()):   \n",
    "    for j in range(1, results[\"Dataset\"].nunique()):   \n",
    "        axes.axes[i,j].get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"paper_figures/engine_comparison_{estimator_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595674f-c68d-4bcf-96d5-e35fecd4fcaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_list = [\n",
    "#    (\"EEIMVC\", \"matlab\", \"embedding_\"),\n",
    "#    (\"SIMCADC\", \"matlab\", \"embedding_\"),\n",
    "    (\"LFIMVC\", \"matlab\", \"embedding_\"),\n",
    "    (\"NEMO\", \"r\", \"affinity_matrix_\"),\n",
    "    (\"IMSR\", \"matlab\", \"embedding_\"),\n",
    "#    (\"DAIMC\", \"matlab\", \"embedding_\"),\n",
    "]\n",
    "total_results = []\n",
    "for (estimator_name, language_comparison, _) in estimator_list:\n",
    "    results = pd.read_csv(f\"tutorials/engine_comparison_{estimator_name}.csv\")\n",
    "    results = prepare_visualizations(results=results)\n",
    "    results[\"Algorithm\"] = estimator_name\n",
    "    if estimator_name == \"NEMO\":\n",
    "        results = results.sort_values(\"Engine\", ascending=True)\n",
    "    total_results.append(results[(results[\"Metric\"] == \"Adjusted Mutual Information\") & (results[\"Engine\"] != \"Both\")])\n",
    "total_results = pd.concat(total_results)\n",
    "total_results[\"Split\"] = total_results[\"Algorithm\"] + total_results[\"Engine\"]\n",
    "total_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b80f10-fd05-4180-9f04-f47bef4baa0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colorblind_palette = sns.color_palette(\"colorblind\")\n",
    "n_estimators = total_results[\"Algorithm\"].unique()\n",
    "estimator_colors_dict = {estimator:colorblind_palette[i] \n",
    "                         for i, estimator in enumerate(n_estimators)}\n",
    "estimator_colors_dict = {mix: col for mix in total_results[\"Split\"]\n",
    "                         for est, col in estimator_colors_dict.items() if mix.startswith(est)}\n",
    "estimator_markers_dict = {estimator:[\"o\", \"+\", \"x\", \"*\", \"1\", \"2\"][i]\n",
    "                          for i, estimator in enumerate(n_estimators)}\n",
    "estimator_markers_dict = {mix: col for mix in total_results[\"Split\"]\n",
    "                          for est, col in estimator_markers_dict.items() if mix.startswith(est)}\n",
    "engine_linestyles_dict = {\"Python\": \"-\", \"Matlab\": \"--\", \"R\": \":\"}\n",
    "engine_linestyles_dict = {mix: col for mix in total_results[\"Split\"] \n",
    "                          for eng, col in engine_linestyles_dict.items() if mix.endswith(eng)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01912cc2-a465-4929-a98f-5a2e06082e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=total_results, col= \"Dataset\", col_wrap=5, dropna=True, legend_out=False,\n",
    "                     sharey=False, despine=False, ylim=(-0.05, 1.05)).map_dataframe(\n",
    "    sns.pointplot, x=\"Incomplete samples (\\%)\", y= \"Value\", hue= \"Split\", dodge=True,\n",
    "    palette= estimator_colors_dict, linestyles= list(engine_linestyles_dict.values()),\n",
    "    markers=list(estimator_markers_dict.values()), capsize= 0.05, seed= 42)\n",
    "\n",
    "ax_legend = g.axes.flatten()[-1]\n",
    "handles = [plt.Line2D([0], [0], marker=marker, color=col, lw=0, markersize=5, markerfacecolor=col)\n",
    "           for i, (_, col, marker) in enumerate(\n",
    "               zip(n_estimators, colorblind_palette, [\"o\", \"+\", \"x\", \"*\", \"1\", \"2\"]))]\n",
    "new_legend = ax_legend.legend(handles=handles,\n",
    "                              labels=n_estimators.tolist(),\n",
    "                              title=\"Algorithm\", loc=\"upper left\")\n",
    "ax_legend.add_artist(new_legend)\n",
    "handles = [plt.Line2D([0], [0], color='black', lw=2, linestyle=linestyle)\n",
    "           for linestyle in np.unique(list(engine_linestyles_dict.values()))]\n",
    "new_legend = ax_legend.legend(handles=handles, \n",
    "                              labels=total_results[\"Engine\"].unique().tolist(),\n",
    "                              title=\"Engine\", loc=\"upper right\")\n",
    "ax_legend.add_artist(new_legend)\n",
    "\n",
    "for ax, ylabel in zip(g.axes, total_results[\"Metric\"].unique()):\n",
    "    ax.set_ylabel(ylabel)\n",
    "for ax, title in zip(g.axes, total_results[\"Dataset\"].unique()):\n",
    "    ax.set_title(title)\n",
    "for i in range(1, total_results[\"Dataset\"].nunique()): \n",
    "    g.axes[i].get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"engine_comparison_joint.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
