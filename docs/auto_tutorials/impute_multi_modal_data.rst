
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/impute_multi_modal_data.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorials_impute_multi_modal_data.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_impute_multi_modal_data.py:


=============================================================
Impute incomplete modality- and feature-wise multi-modal data
=============================================================

When the learning algorithms cannot directly handle missing data, imputation methods become essential to allow
their application. Thus, `iMML` has a module designed for filling missing data, which can be particularly useful
when using external methods that are unable to handle missing values directly.

In this tutorial, we will explore how to use `iMML` to impute an incomplete multi-modal dataset and how to
benchmark imputation quality against a simple baseline.

What you will learn:

- How to represent your dataset as Xs (a list of per‑modality matrices).
- How to simulate block‑wise and feature‑wise missingness with ``Amputer`` and simple masks.
- How to build an imputation pipeline with StandardScaler + ``MOFAImputer``.
- How to compare ``MOFAImputer`` to a baseline mean imputer using Mean Absolute Error (MAE).
- How to visualize missingness before and after imputation.

This tutorial is fully reproducible and uses a small synthetic dataset. You can easily
replace the data‑loading section with your own data following the same structure.

.. GENERATED FROM PYTHON SOURCE LINES 24-29

.. code-block:: Python


    # sphinx_gallery_thumbnail_number = 3

    # License: BSD 3-Clause License








.. GENERATED FROM PYTHON SOURCE LINES 30-32

Step 1: Import required libraries
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 32-46

.. code-block:: Python


    from sklearn.datasets import make_classification
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.impute import SimpleImputer
    from sklearn.metrics import mean_absolute_error
    import numpy as np
    import pandas as pd

    from imml.impute import MOFAImputer
    from imml.preprocessing import MultiModTransformer
    from imml.ampute import Amputer
    from imml.visualize import plot_missing_modality








.. GENERATED FROM PYTHON SOURCE LINES 47-57

Step 2: Load the dataset
^^^^^^^^^^^^^^^^^^^^^^^^
For reproducibility, we generate a small synthetic classification dataset and split the features into two
modalities (Xs[0], Xs[1]).

Using your own data:

- Represent your dataset as a Python list Xs, one entry per modality.
- Each Xs[i] should be a 2D array-like (pandas DataFrame or NumPy array) of shape (n_samples, n_features_i).
- All modalities must refer to the same samples and be aligned by row.

.. GENERATED FROM PYTHON SOURCE LINES 57-70

.. code-block:: Python


    random_state = 42
    X, y = make_classification(n_samples=50, random_state=random_state, n_clusters_per_class=1, n_classes=3)
    X, y = pd.DataFrame(X), pd.Series(y)
    X.columns = X.columns.astype(str)
    # Two modalities: first 10 features and last 10 features
    Xs = [X.iloc[:, :10], X.iloc[:, 10:]]
    names= ["Modality A", "Modality B"]
    print("Samples:", len(Xs[0]), "\t", "Modalities:", len(Xs), "\t", "Features:", [X.shape[1] for X in Xs])
    n_clusters = len(np.unique(y))
    y.value_counts()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Samples: 50      Modalities: 2   Features: [10, 10]

    0    17
    1    17
    2    16
    Name: count, dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 71-76

Step 3: Impute missing data
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
We build an imputation pipeline with two stages:
1) Standardize features per modality (helps MOFA training and makes features comparable).
2) Impute missing modalities with ``MOFAImputer``, which learns shared latent factors across modalities.

.. GENERATED FROM PYTHON SOURCE LINES 76-79

.. code-block:: Python


    amputed_Xs = Amputer(p= 0.3, mechanism="mcar", random_state=random_state).fit_transform(Xs)








.. GENERATED FROM PYTHON SOURCE LINES 80-81

Observe how missing modalities look:

.. GENERATED FROM PYTHON SOURCE LINES 81-88

.. code-block:: Python

    _ = plot_missing_modality(Xs=amputed_Xs, sort=False)

    n_components = 4
    pipeline = make_pipeline(
        MultiModTransformer(StandardScaler().set_output(transform="pandas")),
        MOFAImputer(n_components=n_components, random_state=random_state)
    )



.. image-sg:: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_001.png
   :alt: impute multi modal data
   :srcset: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 89-90

Observe how all modalities are now filled:

.. GENERATED FROM PYTHON SOURCE LINES 90-94

.. code-block:: Python

    imputed_Xs = pipeline.fit_transform(amputed_Xs)
    _ = plot_missing_modality(Xs=imputed_Xs, sort=False)





.. image-sg:: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_002.png
   :alt: impute multi modal data
   :srcset: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 95-105

Step 4: Benchmark imputation accuracy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
We now compare ``MOFAImputer`` with a simple baseline (feature‑wise mean imputation).
Design:

- We introduce both modality‑wise (block) and feature‑wise missingness.
- For each missingness rate p, we repeat the procedure 5 times with different seeds.
- We report Mean Absolute Error (MAE) only on entries that were truly missing.
- For ``MOFAImputer``, we standardize before fitting and then invert the scaling to compute MAE in the original space.


.. GENERATED FROM PYTHON SOURCE LINES 105-153

.. code-block:: Python

    ps = np.arange(0.1, 0.8, 0.2)
    n_times = 5
    methods = ["MOFAImputer", "MeanImputer"]
    all_metrics = []

    for algorithm in methods:
        for p in ps:
            missing_percentage = int(p*100)
            for i in range(n_times):
                ampute = True
                while ampute: # avoid those iterations where a sample has no available data
                    amputed_Xs = Amputer(p=p, random_state=i).fit_transform(Xs)
                    for X in amputed_Xs:
                        mask = np.random.default_rng(i).choice([True, False], p= [p,1-p], size = X.shape)
                        X.iloc[mask] = np.nan
                    if pd.concat(amputed_Xs, axis=1).isna().all(axis=1).any():
                        i += n_times
                    else:
                        ampute = False
                if algorithm == "MeanImputer":
                    pipeline = make_pipeline(
                        MultiModTransformer(SimpleImputer().set_output(transform="pandas"))
                    )
                else:
                    normalizer = StandardScaler()
                    pipeline = make_pipeline(
                        MultiModTransformer(StandardScaler().set_output(transform="pandas")),
                        MOFAImputer(n_components = n_components, random_state=i))
                masks = [np.isnan(amputed_X) for amputed_X in amputed_Xs]
                imputed_Xs = pipeline.fit_transform(amputed_Xs)
                transformer_list = pipeline[0].transformer_list_
                if algorithm != "MeanImputer":
                    imputed_Xs = [pd.DataFrame(transformer.inverse_transform(X), index=X.index, columns=X.columns)
                                  for X, transformer in zip(imputed_Xs, transformer_list)]
                metric = np.mean([mean_absolute_error(transformed_X.values[mask], imputed_X.values[mask])
                                  for transformed_X,imputed_X,mask in zip(Xs, imputed_Xs, masks)])
                result = {
                    "Method": algorithm,
                    'Missing rate (%)': int(p*100),
                    "Iteration": i,
                    "Mean Absolute Error": metric,
                }
                all_metrics.append(result)

    df = pd.DataFrame(all_metrics)
    df = df.sort_values(["Method", "Missing rate (%)", "Iteration"], ascending=[True, True, True])
    df.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Method</th>
          <th>Missing rate (%)</th>
          <th>Iteration</th>
          <th>Mean Absolute Error</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>MOFAImputer</td>
          <td>10</td>
          <td>0</td>
          <td>0.662609</td>
        </tr>
        <tr>
          <th>1</th>
          <td>MOFAImputer</td>
          <td>10</td>
          <td>1</td>
          <td>0.695769</td>
        </tr>
        <tr>
          <th>2</th>
          <td>MOFAImputer</td>
          <td>10</td>
          <td>2</td>
          <td>0.725170</td>
        </tr>
        <tr>
          <th>3</th>
          <td>MOFAImputer</td>
          <td>10</td>
          <td>3</td>
          <td>0.781863</td>
        </tr>
        <tr>
          <th>4</th>
          <td>MOFAImputer</td>
          <td>10</td>
          <td>4</td>
          <td>0.679923</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 154-155

Let's now visualize the results.

.. GENERATED FROM PYTHON SOURCE LINES 155-161

.. code-block:: Python

    g = df.groupby(["Method", "Missing rate (%)"])["Mean Absolute Error"]
    stats = g.agg(mean="mean", sem=lambda x: x.std(ddof=1) / np.sqrt(len(x))).reset_index()
    mean_wide = stats.pivot(index="Missing rate (%)", columns="Method", values="mean")
    sem_wide  = stats.pivot(index="Missing rate (%)", columns="Method", values="sem")
    ax = mean_wide.plot(yerr=sem_wide, marker="o", capsize=3, ylabel="Mean Absolute Error")




.. image-sg:: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_003.png
   :alt: impute multi modal data
   :srcset: /auto_tutorials/images/sphx_glr_impute_multi_modal_data_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 162-167

Summary of results
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Across runs and missingness levels, ``MOFAImputer`` generally achieves lower MAE than the mean‑imputation baseline
at low‑to‑moderate missing rates, reflecting its ability to infer shared latent structure across modalities.
As the missing rate becomes very high, both methods degrade and the gap narrows because little signal remains.

.. GENERATED FROM PYTHON SOURCE LINES 169-175

Conclusion
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Many multi‑modal learning algorithms expect fully observed inputs, making imputation a practical necessity in
real‑world workflows. ``MOFAImputer`` offers a principled, cross‑modal approach that tends to outperform simple
baselines when missingness is not extreme. Thus, `ìMML` can be used for applying less robuts algorithms to
real-world applications.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 5.280 seconds)


.. _sphx_glr_download_auto_tutorials_impute_multi_modal_data.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: impute_multi_modal_data.ipynb <impute_multi_modal_data.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: impute_multi_modal_data.py <impute_multi_modal_data.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: impute_multi_modal_data.zip <impute_multi_modal_data.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
