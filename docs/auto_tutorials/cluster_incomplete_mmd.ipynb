{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Clustering a multi-modal dataset\n\nClustering involves grouping samples into distinct groups. In this tutorial, we show how to use `iMML` to\nperform clustering on a multi-modal dataset. We also demonstrate how to work with incomplete multi-modal data,\nwhere some samples are missing one or more modalities, and how to benchmark the impact of missingness.\n\nWhat you will learn:\n\n- How to represent a dataset with multiple modalities (Xs: list of data matrices).\n- How to build an `iMML` pipeline with preprocessing and clustering.\n- How to evaluate clustering quality with Adjusted Mutual Information (AMI).\n- How to simulate missing modalities (amputation) and visualize missingness.\n- How to benchmark robustness against increasing missing-data rates.\n\nThis tutorial is fully reproducible and uses a small synthetic dataset. You can easily\nreplace the data-loading section with your own data following the same structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 1\n\n# License: BSD 3-Clause License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import required libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import ConfusionMatrixDisplay, adjusted_mutual_info_score\nimport numpy as np\nimport pandas as pd\n\nfrom imml.preprocessing import MultiModTransformer, NormalizerNaN\nfrom imml.ampute import Amputer\nfrom imml.cluster import EEIMVC\nfrom imml.visualize import plot_missing_modality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load the dataset\nFor reproducibility, we generate a small synthetic classification dataset and split the features into two\nmodalities (Xs[0], Xs[1]).\n\nUsing your own data:\n\n- Represent your dataset as a Python list Xs, one entry per modality.\n- Each Xs[i] should be a 2D array-like (pandas DataFrame or NumPy array) of shape (n_samples, n_features_i).\n- All modalities must refer to the same samples and be aligned by row.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "random_state = 42\nX, y = make_classification(n_samples=50, random_state=random_state, n_clusters_per_class=1, n_classes=3)\nX, y = pd.DataFrame(X), pd.Series(y)\n# Two modalities: first 10 features and last 10 features\nXs = [X.iloc[:, :10], X.iloc[:, 10:]]\nprint(\"Samples:\", len(Xs[0]), \"\\t\", \"Modalities:\", len(Xs), \"\\t\", \"Features:\", [X.shape[1] for X in Xs])\nn_clusters = len(np.unique(y))\ny.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Clustering\nWe show how to cluster the multi-modal data using `iMML`, in this case, using the algorithm ``EEIMVC``. For this\nexample, we build a pipeline where we first normalize the data and then the samples are clustered.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = make_pipeline(\n    MultiModTransformer(NormalizerNaN()),\n    EEIMVC(n_clusters = n_clusters, random_state=random_state)\n)\nlabels = pipeline.fit_predict(Xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clustering performance is evaluated using the Adjusted Mutual Information (AMI) score, which measures the\nagreement between predicted clusters and the ground truth, independent of label permutations. We also plot a\nconfusion matrix to visually assess the alignment between predicted clusters and true labels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=labels)\nprint(\"Adjusted Mutual Information Score:\", adjusted_mutual_info_score(labels_true=y, labels_pred=labels))\npd.Series(labels).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The clustering was quite effective, achieving an AMI score close to 0.5. Note that in clustering, the actual label\nvalues are arbitrary, only the grouping structure matters.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Simulate missing data (Amputation)\nAs we mentioned, `iMML` can be used also for incomplete multi-modal learning, Using ``Amputer`` in `iMML`, we\nrandomly introduce missing data to simulate a scenario where some modalities are missing. Here, 20% of\nthe samples will be incomplete.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = 0.2\namputed_Xs = Amputer(p= p, mechanism=\"mcar\", random_state=42).fit_transform(Xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can visualize which modalities are missing using a binary color map (white for missing modalities, black\nfor available modalities). Each row is a sample; each column is a modality.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = plot_missing_modality(Xs=amputed_Xs, sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Clustering with missing data\nNow, we repeat the clustering analysis, but this time with the amputed (incomplete) data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = make_pipeline(\n    MultiModTransformer(NormalizerNaN()),\n    EEIMVC(n_clusters = n_clusters, random_state=random_state)\n)\nlabels = pipeline.fit_predict(amputed_Xs)\n\nConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=labels)\nprint(\"Adjusted Mutual Information Score:\", adjusted_mutual_info_score(labels_true=y, labels_pred=labels))\npd.Series(labels).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the clustering performance decreased. However, it remains reasonably good.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Benchmarking\nWe now compare performance with and without missing data. We also include a simple baseline where\nmissing values are first imputed with the feature-wise mean. We repeat the experiments 5 times\nacross increasing missingness to obtain more robust estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ps = np.arange(0., 1., 0.2)\nn_times = 5\nmethods = [\"No prior imputation\", \"Baseline imputation\"]\nall_metrics = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for method in methods:\n    for p in ps:\n        for i in range(n_times):\n            pipeline = make_pipeline(\n                MultiModTransformer(NormalizerNaN().set_output(transform=\"pandas\")),\n                EEIMVC(n_clusters=n_clusters, random_state=i))\n            if method == \"Baseline imputation\":\n                pipeline = make_pipeline(\n                    MultiModTransformer(SimpleImputer().set_output(transform=\"pandas\")),\n                    *pipeline)\n            pipeline = make_pipeline(Amputer(p=p, mechanism=\"mcar\", random_state=i), *pipeline)\n            clusters = pipeline.fit_predict(Xs)\n            metric = adjusted_mutual_info_score(labels_true=y, labels_pred=clusters)\n            result = {\n                \"Method\": method,\n                \"Incomplete samples (%)\": int(p*100),\n                \"Iteration\": i,\n                \"AMI\": metric,\n            }\n            all_metrics.append(result)\n\ndf = pd.DataFrame(all_metrics)\ndf = df.sort_values([\"Method\", \"Incomplete samples (%)\", \"Iteration\"], ascending=[True, True, True])\ndf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = df.groupby([\"Method\", \"Incomplete samples (%)\"])[\"AMI\"]\nstats = g.agg(mean=\"mean\", sem=lambda x: x.std(ddof=1) / np.sqrt(len(x))).reset_index()\nmean_wide = stats.pivot(index=\"Incomplete samples (%)\", columns=\"Method\", values=\"mean\")\nsem_wide  = stats.pivot(index=\"Incomplete samples (%)\", columns=\"Method\", values=\"sem\")\nax = mean_wide.plot(yerr=sem_wide, marker=\"o\", capsize=3, ylabel=\"Adjusted mutual information\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The adjusted mutual information (AMI) indicates how well the clustering aligns with the ground truth.\nAMI is 1 when partitions are identical; random partitions have an expected AMI around 0 on average and\ncan be negative. Here we compare ``EEIMVC`` with a simple baseline (feature-wise mean imputation)\nacross missingness rates from 0% to 80%. We report the mean over 5 repetitions with a\nstandard-error-of-the-mean (SEM) interval.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of results\nOverall, both approaches yield comparable performance at very low and very high missing rates.\nWhen missingness is low, imputations affect only a small fraction of the data, limiting their negative impact.\nConversely, at extremely high missingness, the signal-to-noise ratio deteriorates to the point where both approaches\nare similarly constrained by data quality.\nWith intermediate rates, ``EEIMVC`` tends to reach a better clustering performance, highlighting its robustness for\nincomplete multi-modal datasets.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nThis example shows how `iMML` supports clustering of multi-modal datasets, including scenarios with missing\nmodalities. The pipeline-based design (preprocessing + clustering) and the ability to simulate and visualize\nmissingness make it straightforward to prototype, evaluate, and benchmark real-world multi-modal workflows.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}