
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/multil_modal_data_statistics.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorials_multil_modal_data_statistics.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_multil_modal_data_statistics.py:


=============================================================
Statistics and interaction structure of a multi-modal dataset
=============================================================

A multi-modal dataset can be characterized beyond basic shape information. With `iMML` you can:

- Summarize core properties of each modality (samples, features, completeness).
- Quantify how modalities relate to a target via PID (Partial Information Decomposition):
  Redundancy (shared info), Uniqueness (modality-specific info), and Synergy (info emerging only when modalities are combined).

What you will learn:

- How to describe per‑modality completeness and cross‑modality overlap with get_summary.
- How to compute redundancy, uniqueness, and synergy (PID) with respect to a target.
- How to visualize and interpret PID results.
- How PID generalizes when you have more than two modalities.

This tutorial is fully reproducible and uses a small synthetic dataset. You can easily
replace the data‑loading section with your own data following the same structure.

.. GENERATED FROM PYTHON SOURCE LINES 22-27

.. code-block:: Python


    # sphinx_gallery_thumbnail_number = 2

    # License: BSD 3-Clause License








.. GENERATED FROM PYTHON SOURCE LINES 28-30

Step 1: Import required libraries
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 30-40

.. code-block:: Python


    import copy
    import numpy as np
    import pandas as pd
    from sklearn.datasets import make_classification

    from imml.statistics import pid
    from imml.explore import get_summary
    from imml.visualize import plot_pid








.. GENERATED FROM PYTHON SOURCE LINES 41-51

Step 2: Create or load a multi-modal dataset
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For reproducibility, we generate a small synthetic classification dataset and split the features into two
modalities (Xs[0], Xs[1]).

Using your own data:

- Represent your dataset as a Python list Xs, one entry per modality.
- Each Xs[i] should be a 2D array-like (pandas DataFrame or NumPy array) of shape (n_samples, n_features_i).
- All modalities must refer to the same samples and be aligned by row order or index.

.. GENERATED FROM PYTHON SOURCE LINES 51-59

.. code-block:: Python


    random_state = 42
    X, y = make_classification(n_samples=20, random_state=random_state)
    # Two modalities: first 10 features and last 10 features
    Xs = [X[:, :10], X[:, 10:]]
    print("Samples:", len(Xs[0]), "\t", "Modalities:", len(Xs), "\t", "Features:", [X.shape[1] for X in Xs])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Samples: 20      Modalities: 2   Features: [10, 10]




.. GENERATED FROM PYTHON SOURCE LINES 60-65

Step 3: Summarize the dataset
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The get_summary function provides a compact overview of the multi‑modal dataset. Below we first
make the dataset a bit more complex by introducing some incomplete samples, then show two views:
1) a dictionary aggregated across modalities (one_row=True) and 2) per‑modality counts (one_row=False).

.. GENERATED FROM PYTHON SOURCE LINES 65-76

.. code-block:: Python


    inc_Xs = copy.deepcopy(Xs)
    # Introduce block-wise missingness in a few regions for illustration
    inc_Xs[0][:10, :] = np.nan
    inc_Xs[0][12, 1] = np.nan
    inc_Xs[1][11:13, :] = np.nan
    inc_Xs[1][15:, 3] = np.nan

    summary = get_summary(Xs=inc_Xs, one_row=True, compute_pct=True, return_df=True)
    summary






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Complete samples</th>
          <th>Incomplete samples</th>
          <th>Observed samples per modality</th>
          <th>Missing samples per modality</th>
          <th>% Observed samples per modality</th>
          <th>% Missing samples per modality</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>8</td>
          <td>12</td>
          <td>[10, 18]</td>
          <td>[10, 2]</td>
          <td>[50, 90]</td>
          <td>[50, 10]</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 77-78

Per‑modality view:

.. GENERATED FROM PYTHON SOURCE LINES 78-81

.. code-block:: Python

    summary = get_summary(Xs=inc_Xs, modalities=["Modality A", "Modality B"], one_row=False, compute_pct=True, return_df=True)
    summary






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Complete samples</th>
          <th>Missing samples</th>
          <th>Incomplete samples</th>
          <th>% Complete samples</th>
          <th>% Missing samples</th>
          <th>% Incomplete samples</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>Modality A</th>
          <td>9</td>
          <td>10</td>
          <td>11</td>
          <td>45.0</td>
          <td>50.0</td>
          <td>55.0</td>
        </tr>
        <tr>
          <th>Modality B</th>
          <td>13</td>
          <td>2</td>
          <td>7</td>
          <td>65.0</td>
          <td>10.0</td>
          <td>35.0</td>
        </tr>
        <tr>
          <th>Total</th>
          <td>3</td>
          <td>12</td>
          <td>17</td>
          <td>15.0</td>
          <td>60.0</td>
          <td>85.0</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 82-83

For quick inspection, we can also plot the per‑modality counts. Here we create a bar chart.

.. GENERATED FROM PYTHON SOURCE LINES 83-90

.. code-block:: Python


    summary.index = summary.index.str.replace(" samples", "")
    _ = summary[[c for c in summary.columns if not c.startswith('%')]].plot(
        kind="bar", xlabel="Samples", ylabel="Count", rot=0,
        title="Summary of the multi-modal dataset")





.. image-sg:: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_001.png
   :alt: Summary of the multi-modal dataset
   :srcset: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 91-95

Step 4: Compute PID statistics (Redundancy, Uniqueness, Synergy)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Using pid, we quantify the degree of redundancy, uniqueness, and synergy relating input modalities to the target.
With two input modalities, pid returns a dictionary with keys: "Redundancy", "Uniqueness1", "Uniqueness2", and "Synergy".

.. GENERATED FROM PYTHON SOURCE LINES 95-100

.. code-block:: Python


    rus = pid(Xs=Xs, y=y, random_state=random_state, normalize=True)
    rus  # a dict with keys: Redundancy, Uniqueness1, Uniqueness2, Synergy






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    {'Redundancy': np.float64(0.9989831184204245), 'Uniqueness1': np.float64(-2.803578279148753e-17), 'Uniqueness2': np.float64(-2.4529962183078916e-16), 'Synergy': np.float64(0.0010168815795758136)}



.. GENERATED FROM PYTHON SOURCE LINES 101-105

Step 5: Visualize the PID as a Venn-like diagram
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
You can directly pass the rus dict returned by pid to plot_pid. Alternatively, plot_pid can also compute pid
internally if you pass Xs and y, which is convenient when you want a one‑liner.

.. GENERATED FROM PYTHON SOURCE LINES 105-109

.. code-block:: Python


    rus = {"Redundancy": 0.2, "Synergy": 0.1, "Uniqueness1": 0.45, "Uniqueness2": 0.25}
    fig, ax = plot_pid(rus=rus, modalities=["Modality A", "Modality B"], abb=False)




.. image-sg:: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_002.png
   :alt: multil modal data statistics
   :srcset: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 110-118

Step 6: Interpreting PID results
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- Redundancy: Information about the target available in both modalities. High values suggest overlap.
- Uniqueness1/2: Modality‑specific information about the target. High values suggest complementarity.
- Synergy: Information that emerges only when modalities are combined. High synergy often indicates interactions.

If redundancy is high while uniqueness and synergy are low, this may suggest that the dataset could be more
appropriately analyzed using classical unimodal modeling.

.. GENERATED FROM PYTHON SOURCE LINES 120-124

Step 7: Working with more than two modalities
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
If you have more than two modalities, PID statistics are computed pairwise; pid returns a list of
dictionaries (one per pair). For example, adding a third modality yields three pairwise results.

.. GENERATED FROM PYTHON SOURCE LINES 124-128

.. code-block:: Python

    rus = pid(Xs=Xs + [Xs[0]], y=y, random_state=random_state, normalize=True)
    rus






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [{'Redundancy': np.float64(0.9989831184204245), 'Uniqueness1': np.float64(-2.803578279148753e-17), 'Uniqueness2': np.float64(-2.4529962183078916e-16), 'Synergy': np.float64(0.0010168815795758136)}, {'Redundancy': np.float64(0.9989831184433112), 'Uniqueness1': np.float64(4.1050067855098473e-17), 'Uniqueness2': np.float64(-1.402578336849826e-17), 'Synergy': np.float64(0.001016881556688773)}, {'Redundancy': np.float64(0.9989831183754172), 'Uniqueness1': np.float64(2.102606271973467e-17), 'Uniqueness2': np.float64(4.0053414423886814e-17), 'Synergy': np.float64(0.0010168816245828352)}]



.. GENERATED FROM PYTHON SOURCE LINES 129-139

Conclusion
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
In this tutorial, we:

- Summarized key per‑modality statistics for a multi‑modal dataset.
- Quantified redundancy, uniqueness, and synergy with respect to a target using PID.
- Visualized and interpreted PID, including the multi‑modality (>2) case.

These insights help you understand complementarity and interactions across modalities, informing model design and
feature engineering for downstream multi‑modal learning.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 10.070 seconds)


.. _sphx_glr_download_auto_tutorials_multil_modal_data_statistics.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: multil_modal_data_statistics.ipynb <multil_modal_data_statistics.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: multil_modal_data_statistics.py <multil_modal_data_statistics.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: multil_modal_data_statistics.zip <multil_modal_data_statistics.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
