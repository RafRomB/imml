
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/multil_modal_data_statistics.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorials_multil_modal_data_statistics.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_multil_modal_data_statistics.py:


=============================================================
Statistics and interaction structure of a multi-modal dataset
=============================================================

A multi-modal dataset can be characterized beyond basic shape information. With `iMML` you can:

- Summarize core properties of each modality (samples, features, completeness).
- Quantify how modalities relate to a target via PID (Partial Information Decomposition):
  Redundancy (shared info), Uniqueness (modality-specific info), and Synergy (info emerging only when modalities are combined).

What you will learn:

- How to describe per‑modality completeness and cross‑modality overlap with ``get_summary``.
- How to compute redundancy, uniqueness, and synergy (PID) with respect to a target using ``pid``.
- How to visualize and interpret PID results.
- How PID generalizes when you have more than two modalities.

This tutorial is fully reproducible and uses a small synthetic dataset. You can easily
replace the data‑loading section with your own data following the same structure.

.. GENERATED FROM PYTHON SOURCE LINES 22-27

.. code-block:: Python


    # sphinx_gallery_thumbnail_number = 2

    # License: BSD 3-Clause License








.. GENERATED FROM PYTHON SOURCE LINES 28-30

Step 1: Import required libraries
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 30-40

.. code-block:: Python


    import copy
    import numpy as np
    import pandas as pd
    from sklearn.datasets import make_classification

    from imml.statistics import pid
    from imml.explore import get_summary
    from imml.visualize import plot_pid








.. GENERATED FROM PYTHON SOURCE LINES 41-51

Step 2: Create or load a multi-modal dataset
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For reproducibility, we generate a small synthetic classification dataset and split the features into two
modalities (Xs[0], Xs[1]).

Using your own data:

- Represent your dataset as a Python list Xs, one entry per modality.
- Each Xs[i] should be a 2D array-like (pandas DataFrame or NumPy array) of shape (n_samples, n_features_i).
- All modalities must refer to the same samples and be aligned by row.

.. GENERATED FROM PYTHON SOURCE LINES 51-59

.. code-block:: Python


    random_state = 42
    X, y = make_classification(n_samples=50, random_state=random_state)
    # Two modalities: first 10 features and last 10 features
    Xs = [X[:, :10], X[:, 10:]]
    print("Samples:", len(Xs[0]), "\t", "Modalities:", len(Xs), "\t", "Features:", [X.shape[1] for X in Xs])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Samples: 50      Modalities: 2   Features: [10, 10]




.. GENERATED FROM PYTHON SOURCE LINES 60-65

Step 3: Summarize the dataset
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The ``get_summary`` function provides a compact overview of the multi‑modal dataset. Below we first
make the dataset a bit more complex by introducing some incomplete samples, then show two views:
1) a dataframe aggregated across modalities (one_row=True) and 2) per‑modality counts (one_row=False).

.. GENERATED FROM PYTHON SOURCE LINES 65-76

.. code-block:: Python


    inc_Xs = copy.deepcopy(Xs)
    # Introduce block-wise missingness in a few regions for illustration
    inc_Xs[0][:20, :] = np.nan
    inc_Xs[0][25, 1] = np.nan
    inc_Xs[1][18:22, :] = np.nan
    inc_Xs[1][-15:, 3] = np.nan

    summary = get_summary(Xs=inc_Xs, one_row=True, compute_pct=True, return_df=True)
    summary






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Complete samples</th>
          <th>Incomplete samples</th>
          <th>Observed samples per modality</th>
          <th>Missing samples per modality</th>
          <th>% Observed samples per modality</th>
          <th>% Missing samples per modality</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>28</td>
          <td>22</td>
          <td>[30, 46]</td>
          <td>[20, 4]</td>
          <td>[60, 92]</td>
          <td>[40, 8]</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 77-78

Per‑modality view:

.. GENERATED FROM PYTHON SOURCE LINES 78-81

.. code-block:: Python

    summary = get_summary(Xs=inc_Xs, modalities=["Modality A", "Modality B"], one_row=False, compute_pct=True, return_df=True)
    summary






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Complete samples</th>
          <th>Missing samples</th>
          <th>Incomplete samples</th>
          <th>% Complete samples</th>
          <th>% Missing samples</th>
          <th>% Incomplete samples</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>Modality A</th>
          <td>29</td>
          <td>20</td>
          <td>21</td>
          <td>58.0</td>
          <td>40.0</td>
          <td>42.0</td>
        </tr>
        <tr>
          <th>Modality B</th>
          <td>31</td>
          <td>4</td>
          <td>19</td>
          <td>62.0</td>
          <td>8.0</td>
          <td>38.0</td>
        </tr>
        <tr>
          <th>Total</th>
          <td>12</td>
          <td>22</td>
          <td>38</td>
          <td>24.0</td>
          <td>44.0</td>
          <td>76.0</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 82-83

For quick inspection, we can also plot the per‑modality counts. Here we create a bar chart.

.. GENERATED FROM PYTHON SOURCE LINES 83-90

.. code-block:: Python


    summary.index = summary.index.str.replace(" samples", "")
    _ = summary[[c for c in summary.columns if not c.startswith('%')]].plot(
        kind="bar", xlabel="Samples", ylabel="Count", rot=0,
        title="Summary of the multi-modal dataset")





.. image-sg:: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_001.png
   :alt: Summary of the multi-modal dataset
   :srcset: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 91-96

Step 4: Compute PID statistics (Redundancy, Uniqueness, Synergy)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Using ``pid``, we quantify the degree of redundancy, uniqueness, and synergy relating input modalities to the target.
With two input modalities, ``pid`` returns a dictionary with keys: "Redundancy", "Uniqueness1", "Uniqueness2",
and "Synergy".

.. GENERATED FROM PYTHON SOURCE LINES 96-101

.. code-block:: Python


    rus = pid(Xs=Xs, y=y, random_state=random_state, normalize=True)
    rus  # a dict with keys: Redundancy, Uniqueness1, Uniqueness2, Synergy






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    {'Redundancy': np.float64(0.2165211867463263), 'Uniqueness1': np.float64(0.7743673072618481), 'Uniqueness2': np.float64(0.0009259835942955852), 'Synergy': np.float64(0.008185522397530105)}



.. GENERATED FROM PYTHON SOURCE LINES 102-106

Step 5: Visualize the PID as a Venn-like diagram
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
You can directly pass the rus dict returned by ``pid`` to ``plot_pid``. Alternatively, ``plot_pid`` can also compute
PID internally if you pass Xs and y, which is convenient when you want a one‑liner.

.. GENERATED FROM PYTHON SOURCE LINES 106-110

.. code-block:: Python


    rus = {"Redundancy": 0.2, "Synergy": 0.1, "Uniqueness1": 0.45, "Uniqueness2": 0.25}
    fig, ax = plot_pid(rus=rus, modalities=["Modality A", "Modality B"], abb=False)




.. image-sg:: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_002.png
   :alt: multil modal data statistics
   :srcset: /auto_tutorials/images/sphx_glr_multil_modal_data_statistics_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 111-119

Step 6: Interpreting PID results
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- Redundancy: Information about the target available in both modalities. High values suggest overlap.
- Uniqueness1/2: Modality‑specific information about the target. High values suggest complementarity.
- Synergy: Information that emerges only when modalities are combined. High synergy often indicates interactions.

If redundancy is high while uniqueness and synergy are low, this may suggest that the dataset could be more
appropriately analyzed using classical unimodal modeling.

.. GENERATED FROM PYTHON SOURCE LINES 121-125

Step 7: Working with more than two modalities
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
If you have more than two modalities, PID statistics are computed pairwise; ``pid`` returns a list of
dictionaries (one per pair). For example, adding a third modality yields three pairwise results.

.. GENERATED FROM PYTHON SOURCE LINES 125-129

.. code-block:: Python

    rus = pid(Xs=Xs + [Xs[0]], y=y, random_state=random_state, normalize=True)
    rus






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [{'Redundancy': np.float64(0.2165211867463263), 'Uniqueness1': np.float64(0.7743673072618481), 'Uniqueness2': np.float64(0.0009259835942955852), 'Synergy': np.float64(0.008185522397530105)}, {'Redundancy': np.float64(0.9967118426445922), 'Uniqueness1': np.float64(8.484563903507687e-05), 'Uniqueness2': np.float64(8.484563906632952e-05), 'Synergy': np.float64(0.003118466077306442)}, {'Redundancy': np.float64(0.2165211867513762), 'Uniqueness1': np.float64(0.0009259835942656313), 'Uniqueness2': np.float64(0.7743673072590187), 'Synergy': np.float64(0.008185522395339602)}]



.. GENERATED FROM PYTHON SOURCE LINES 130-140

Conclusion
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
In this tutorial, we:

- Summarized key per‑modality statistics for a multi‑modal dataset.
- Quantified redundancy, uniqueness, and synergy with respect to a target using PID.
- Visualized and interpreted PID, including the multi‑modality (>2) case.

These insights help you understand complementarity and interactions across modalities, informing model design and
feature engineering for downstream multi‑modal learning.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 16.694 seconds)


.. _sphx_glr_download_auto_tutorials_multil_modal_data_statistics.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: multil_modal_data_statistics.ipynb <multil_modal_data_statistics.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: multil_modal_data_statistics.py <multil_modal_data_statistics.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: multil_modal_data_statistics.zip <multil_modal_data_statistics.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
