{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Statistics and interaction structure of a multi-modal dataset\n\nA multi-modal dataset can be characterized beyond basic shape information. With `iMML` you can:\n\n- Summarize core properties of each modality (samples, features, completeness).\n- Quantify how modalities relate to a target via PID (Partial Information Decomposition):\n  Redundancy (shared info), Uniqueness (modality-specific info), and Synergy (info emerging only when modalities are combined).\n\nWhat you will learn:\n\n- How to describe per\u2011modality completeness and cross\u2011modality overlap with get_summary.\n- How to compute redundancy, uniqueness, and synergy (PID) with respect to a target.\n- How to visualize and interpret PID results.\n- How PID generalizes when you have more than two modalities.\n\nThis tutorial is fully reproducible and uses a small synthetic dataset. You can easily\nreplace the data\u2011loading section with your own data following the same structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 2\n\n# License: BSD 3-Clause License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import required libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification\n\nfrom imml.statistics import pid\nfrom imml.explore import get_summary\nfrom imml.visualize import plot_pid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create or load a multi-modal dataset\nFor reproducibility, we generate a small synthetic classification dataset and split the features into two\nmodalities (Xs[0], Xs[1]).\n\nUsing your own data:\n\n- Represent your dataset as a Python list Xs, one entry per modality.\n- Each Xs[i] should be a 2D array-like (pandas DataFrame or NumPy array) of shape (n_samples, n_features_i).\n- All modalities must refer to the same samples and be aligned by row order or index.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "random_state = 42\nX, y = make_classification(n_samples=20, random_state=random_state)\n# Two modalities: first 10 features and last 10 features\nXs = [X[:, :10], X[:, 10:]]\nprint(\"Samples:\", len(Xs[0]), \"\\t\", \"Modalities:\", len(Xs), \"\\t\", \"Features:\", [X.shape[1] for X in Xs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Summarize the dataset\nThe get_summary function provides a compact overview of the multi\u2011modal dataset. Below we first\nmake the dataset a bit more complex by introducing some incomplete samples, then show two views:\n1) a dictionary aggregated across modalities (one_row=True) and 2) per\u2011modality counts (one_row=False).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inc_Xs = copy.deepcopy(Xs)\n# Introduce block-wise missingness in a few regions for illustration\ninc_Xs[0][:10, :] = np.nan\ninc_Xs[0][12, 1] = np.nan\ninc_Xs[1][11:13, :] = np.nan\ninc_Xs[1][15:, 3] = np.nan\n\nsummary = get_summary(Xs=inc_Xs, one_row=True, compute_pct=True, return_df=True)\nsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per\u2011modality view:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary = get_summary(Xs=inc_Xs, modalities=[\"Modality A\", \"Modality B\"], one_row=False, compute_pct=True, return_df=True)\nsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For quick inspection, we can also plot the per\u2011modality counts. Here we create a bar chart.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary.index = summary.index.str.replace(\" samples\", \"\")\n_ = summary[[c for c in summary.columns if not c.startswith('%')]].plot(\n    kind=\"bar\", xlabel=\"Samples\", ylabel=\"Count\", rot=0,\n    title=\"Summary of the multi-modal dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Compute PID statistics (Redundancy, Uniqueness, Synergy)\nUsing pid, we quantify the degree of redundancy, uniqueness, and synergy relating input modalities to the target.\nWith two input modalities, pid returns a dictionary with keys: \"Redundancy\", \"Uniqueness1\", \"Uniqueness2\", and \"Synergy\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rus = pid(Xs=Xs, y=y, random_state=random_state, normalize=True)\nrus  # a dict with keys: Redundancy, Uniqueness1, Uniqueness2, Synergy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Visualize the PID as a Venn-like diagram\nYou can directly pass the rus dict returned by pid to plot_pid. Alternatively, plot_pid can also compute pid\ninternally if you pass Xs and y, which is convenient when you want a one\u2011liner.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rus = {\"Redundancy\": 0.2, \"Synergy\": 0.1, \"Uniqueness1\": 0.45, \"Uniqueness2\": 0.25}\nfig, ax = plot_pid(rus=rus, modalities=[\"Modality A\", \"Modality B\"], abb=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Interpreting PID results\n- Redundancy: Information about the target available in both modalities. High values suggest overlap.\n- Uniqueness1/2: Modality\u2011specific information about the target. High values suggest complementarity.\n- Synergy: Information that emerges only when modalities are combined. High synergy often indicates interactions.\n\nIf redundancy is high while uniqueness and synergy are low, this may suggest that the dataset could be more\nappropriately analyzed using classical unimodal modeling.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Working with more than two modalities\nIf you have more than two modalities, PID statistics are computed pairwise; pid returns a list of\ndictionaries (one per pair). For example, adding a third modality yields three pairwise results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rus = pid(Xs=Xs + [Xs[0]], y=y, random_state=random_state, normalize=True)\nrus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nIn this tutorial, we:\n\n- Summarized key per\u2011modality statistics for a multi\u2011modal dataset.\n- Quantified redundancy, uniqueness, and synergy with respect to a target using PID.\n- Visualized and interpreted PID, including the multi\u2011modality (>2) case.\n\nThese insights help you understand complementarity and interactions across modalities, informing model design and\nfeature engineering for downstream multi\u2011modal learning.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}